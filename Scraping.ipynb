{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3, requests, json, multiprocessing, time, urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppURLopener(urllib.request.FancyURLopener):\n",
    "    version = \"Mozilla/6.0\"\n",
    "\n",
    "OPENER = AppURLopener()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blockchainhealthcarereview.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_BHM = 'https://blockchainhealthcarereview.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = OPENER.open(URL_BHM)\n",
    "soup = BeautifulSoup(response.read(),\"html.parser\")\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = open('blockchainhealthcarereview_new.txt','w')\n",
    "for topic in tqdm(soup.find(\"div\",{'class': 'mh-footer-widget widget_categories'}).find_all('option',{'class':\"level-0\"})):\n",
    "    temp_url = '/category/'+'-'.join(topic.text.lower().split()[:-1])\n",
    "    print(temp_url)\n",
    "    \n",
    "    for i in range(1,15):\n",
    "        try:\n",
    "            response = OPENER.open(URL_BHM+temp_url+'/page/'+str(i))\n",
    "            category_soup = BeautifulSoup(response.read(),\"html.parser\")\n",
    "#             print(URL_BHM+temp_url+'/page/'+str(i))\n",
    "        # need paginator\n",
    "\n",
    "\n",
    "            for article in category_soup.find(\"div\",{'class': 'mh-wrapper'}).find_all('article'):\n",
    "                href = article.find('a',href=True)['href']\n",
    "#                 print(href)\n",
    "                try:\n",
    "#                     print(article.find('a')['title'].strip())\n",
    "                    saver.write(article.find('a')['title'].strip()+'.')\n",
    "                except:\n",
    "#                     print(article.find('header').find('a').text.strip())\n",
    "                    saver.write(article.find('header').find('a').text.strip()+'.')\n",
    "                    \n",
    "                article_response = OPENER.open(href)\n",
    "                article_soup = BeautifulSoup(article_response.read(),\"html.parser\")\n",
    "    \n",
    "                try:\n",
    "                    for i in article_soup.find(\"div\",{'class': 'post-content'}).find_all(['p','ul','h1','h2','h3']):\n",
    "#                         print(i.text.strip())\n",
    "                        saver.write(i.text.strip().replace('\\n', ' '))\n",
    "                except:\n",
    "                    for i in article_soup.find(\"div\",{'class': 'entry-content'}).find_all(['p','ul','h1','h2','h3']):\n",
    "#                         print(i.text.strip())\n",
    "                        saver.write(i.text.strip().replace('\\n', ' '))\n",
    "                saver.write('\\n')\n",
    "\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "saver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
